1. 正则表达式模型

优点：

简单直接，性能高，几乎无依赖。

对 格式固定、模式明显 的文本提取非常高效。

易于快速原型验证。

缺点：

表达能力有限，无法理解语义。

可维护性差，规则一多就难以管理。

容易过拟合特定场景，稍微变化就失效。

适用场景：

日志解析、邮件地址/手机号提取、固定模式的表单校验。

小规模、规则清晰的文本处理。

2. TF-IDF 机器学习模型

优点：

实现简单，经典文本表示方法，广泛支持。

训练成本低，适合中小数据集。

对关键词驱动的任务（如文本分类、搜索）有一定效果。

缺点：

只基于词频，忽略词序、上下文。

语义表达力弱，难以处理同义词、多义词。

对长文本效果差（稀疏向量）。

适用场景：

文本分类、信息检索、推荐系统的基础检索层。

数据规模小、计算资源有限时的 baseline。

3. BERT 模型（预训练语言模型）

优点：

上下文理解强，捕捉语义关系。

可以微调到各种 NLP 任务（分类、实体识别、问答等）。

开源生态丰富（transformers 库、预训练模型）。

缺点：

训练 & 推理成本高（需要 GPU/TPU）。

模型大，部署资源消耗大。

微调需要一定规模标注数据。

适用场景：

语义搜索、意图识别、文本匹配、问答系统。

数据量足够，且需要较高语义理解精度时。

4. Prompt 模型（大语言模型调用，如 GPT）

优点：

无需标注数据，零样本/少样本 即可应用。

语义理解最强，可以泛化多任务。

交互灵活，支持复杂推理和生成。

缺点：

成本高（调用 API 或部署大模型）。

输出不稳定，需要 prompt 工程调优。

难以在资源有限环境下部署本地。

适用场景：

开发快速原型、自动化问答、文档生成。

语义复杂、场景多变，传统 ML/NLP 难以覆盖时。

需要多任务统一处理的系统。