
# 文本分类方法对比：Regex, TF-IDF, BERT, GPT


对比四种不同级别的文本分类方法：基于规则的正则表达式、传统的机器学习方法（以TF-IDF为代表）、预训练的深度语言模型（BERT）以及生成式预训练模型（GPT）。

## 总结对比表

| 方法 | 核心思想 | 优点 | 缺点 | 适用场景 |
| :--- | :--- | :--- | :--- | :--- |
| **Regex** | 规则匹配 | 简单、快速、零样本、精确 | 无法泛化、难维护、无语义理解 | 规则明确、模式固定的提取任务 |
| **TF-IDF** | 统计权重 | 可解释、效率高、需数据少 | 无语义、稀疏特征、依赖特征工程 | 小数据集、基线模型、可解释性要求高 |
| **BERT** | 上下文编码 | 性能顶尖、语义理解强、迁移学习 | 计算成本高、黑盒、需微调数据 | 高精度要求的复杂分类任务 |
| **GPT** | 生成式提示 | 零/少样本能力强、极其灵活 | 成本极高、结果不可控、延迟高 | 零样本、标签多变、探索性分析 |

## 技术选型建议

- **从简单开始**：先用 Regex 或 TF-IDF 建立基线，看性能是否满足要求。
- **追求精度**：如果基线性能不足，且有标注数据和算力，**BERT是首选**。
- **缺乏标注数据**：如果几乎没有标注数据，且任务简单，可以尝试设计规则（Regex）。如果任务复杂且预算充足，可以尝试**GPT系列的零样本/少样本能力**。
- **平衡性能与成本**：在边缘设备部署时，TF-IDF可能是更实际的选择；在云端且追求极致效果时，选择BERT。
