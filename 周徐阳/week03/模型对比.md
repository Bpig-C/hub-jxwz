### 1. bert.py(基于中文BERT预训练模型/使用GPU加速批处理)
#### 优点
- **语义理解强**：预训练模型具有丰富的语言知识
- **上下文建模**：能够理解词汇在句子中的含义
- **泛化能力好**：对未见过的表达方式有较好的适应性
- **无需特征工程**：端到端学习，自动提取最优特征
- **效果通常最佳**：在大多数NLP任务上表现优异

#### 缺点
- **计算资源需求大**：需要GPU支持，内存消耗较高
- **推理速度较慢**：相比传统方法响应时间更长
- **模型体积大**：预训练模型文件通常几百MB到几GB
- **黑盒特性**：模型决策过程难以解释
- **部署复杂**：需要深度学习框架和相关依赖

### 2. prompt.py(利用TF-IDF找到最相似的训练样本作为示例)
#### 优点
- **零样本能力**：无需专门训练即可处理新任务
- **灵活性极高**：通过改变提示词快速适应新需求
- **少样本学习**：几个例子就能理解任务模式
- **自然语言交互**：可以通过自然语言描述分类要求
- **持续改进**：模型能力随着底层LLM升级而提升

#### 缺点
- **推理成本高**：每次调用都需要大模型推理
- **响应时间不稳定**：依赖网络和模型服务状态
- **输出格式不稳定**：可能需要额外的输出解析和校验
- **依赖外部服务**：需要稳定的模型API服务
- **成本控制难**：按调用次数计费，大量请求成本较高

### 3. regex_rule.py(基于预定义的关键词规则进行文本匹配)
#### 优点
- **响应速度极快**：无需模型加载，直接字符串匹配
- **资源消耗最少**：几乎不占用内存和CPU
- **逻辑透明**：规则完全可解释，便于调试
- **易于维护**：添加新规则或修改现有规则都很简单
- **部署简单**：无需额外依赖，适合轻量级场景

#### 缺点
- **覆盖范围有限**：当前只定义了2个类别的规则
- **泛化能力差**：无法处理同义词、语序变化等语言变化
- **召回率低**：只能匹配预定义的关键词组合
- **维护成本高**：需要人工不断添加和优化规则
- **无法处理复杂语义**：不能理解上下文和隐含意图

### 4. tfidf_ml.py(使用jieba进行中文分词)
#### 优点
- **训练速度快**：相比深度学习模型训练时间短
- **模型体积小**：pkl文件较小，便于部署
- **特征可解释**：TF-IDF权重可以分析关键词重要性
- **成熟稳定**：基于经典算法，技术风险低
- **适合中等数据量**：在数据量不大时表现良好

#### 缺点
- **特征表示局限**：无法捕获词汇间的语义关系
- **上下文理解弱**：词袋模型忽略词序和语法结构
- **需要人工特征工程**：分词和停用词处理需要专门优化
- **对新词敏感**：OOV（词汇表外）词汇处理能力差
- **长文本效果不佳**：TF-IDF在短文本上表现更好
