这四种模型代表了自然语言处理发展的阶段，从规则驱动到统计学习再到深度学习。


1.正则表达式模型：该模型是基于预定义规则的模式匹配工具。

优点：对格式固定的文本提取非常有效，规则由人定义，不需要标注数据，直接编写规则表达式即可。
缺点：只能识别预定义的模式，稍有不同的表达就无法匹配，可维护性不高，规则多就难以管理。

2.TF-IDF模型
优点：实现简单，经典文本表示方法，广泛支持，训练成本低，适合中小数据集。
缺点：使用传统词向量的方法，特征向量维度高，稀疏，不会存储单词的上下文和次序，无法处理一词多义，同义词等问题。

3.BERT模型

优点：能够理解上下文、一词多义、语义相似性，可以微调到各种 NLP 任务（分类、实体识别、问答等）。基于注意力机制，真正理解词汇在具体语境中的含义。
缺点：训练和推理成本高（需要 GPU/TPU）。模型大，部署资源消耗大。微调需要一定规模标注数据。

4. Prompt 模型

优点：无需微调：通过精心设计的提示词直接使用预训练模型，减少训练成本。可以用同一模型解决多种不同类型的任务，无需或只需少量示例就能完成新任务，
通过修改提示词可以灵活调整模型行为。

缺点：调用API或部署大模型成本高，输出结果不稳定，决策过程更加黑盒。




